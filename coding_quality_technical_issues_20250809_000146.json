{
  "unified_system": {
    "basic_metrics": {
      "total_lines": 535,
      "code_lines": 438,
      "classes": 6,
      "functions": 23,
      "imports": 13,
      "comments": 47,
      "docstrings": 56
    },
    "complexity_issues": [
      {
        "type": "long_function",
        "function": "get_data",
        "line": 262,
        "length": 52,
        "severity": "medium"
      }
    ],
    "performance_issues": [
      {
        "type": "performance",
        "pattern": "\\.exists\\(\\)",
        "line": 125,
        "code": "if not base_path.exists():",
        "issue": "ファイル存在確認",
        "impact": "ファイルシステムアクセス",
        "severity": "low"
      },
      {
        "type": "performance",
        "pattern": "\\.rglob\\(.*\\)",
        "line": 130,
        "code": "for file_path in base_path.rglob('*'):",
        "issue": "再帰的ディレクトリスキャン",
        "impact": "ファイル数に比例して処理時間増加",
        "severity": "high"
      },
      {
        "type": "performance",
        "pattern": "for.*in.*\\.rglob",
        "line": 130,
        "code": "for file_path in base_path.rglob('*'):",
        "issue": "再帰的スキャンでのループ処理",
        "impact": "大量ファイル時のパフォーマンス劣化",
        "severity": "high"
      },
      {
        "type": "performance",
        "pattern": "\\.stat\\(\\)",
        "line": 151,
        "code": "stat = file_path.stat()",
        "issue": "ファイル統計情報取得",
        "impact": "ファイルシステムI/O待機",
        "severity": "low"
      },
      {
        "type": "performance",
        "pattern": "\\.stat\\(\\)",
        "line": 175,
        "code": "if file_path.stat().st_size > self.max_file_size:",
        "issue": "ファイル統計情報取得",
        "impact": "ファイルシステムI/O待機",
        "severity": "low"
      },
      {
        "type": "performance",
        "pattern": "\\.exists\\(\\)",
        "line": 180,
        "code": "if not file_path.exists() or not file_path.is_file():",
        "issue": "ファイル存在確認",
        "impact": "ファイルシステムアクセス",
        "severity": "low"
      },
      {
        "type": "performance",
        "pattern": "hashlib\\..*\\(",
        "line": 253,
        "code": "hasher = hashlib.sha256()",
        "issue": "ファイルハッシュ計算",
        "impact": "ファイルサイズに比例した処理時間",
        "severity": "medium"
      },
      {
        "type": "performance",
        "pattern": "\\.exists\\(\\)",
        "line": 482,
        "code": "valid_paths = [p for p in base_paths if p.exists() or p == Path('.')]",
        "issue": "ファイル存在確認",
        "impact": "ファイルシステムアクセス",
        "severity": "low"
      },
      {
        "type": "performance_impact",
        "issue": "1箇所での全ファイルスキャン",
        "estimated_files": 990,
        "estimated_operations": 5940,
        "severity": "critical",
        "improvement_potential": "特定ファイル検索に変更で5938回の処理削減可能"
      }
    ],
    "maintainability_issues": [
      {
        "type": "hardcoded_values",
        "line": 74,
        "code": "cache_ttl_seconds: int = 3600  # デフォルト1時間",
        "description": "ハードコーディング値",
        "severity": "medium",
        "pattern": "\\d{4}"
      },
      {
        "type": "hardcoded_values",
        "line": 74,
        "code": "cache_ttl_seconds: int = 3600  # デフォルト1時間",
        "description": "ハードコーディング値",
        "severity": "medium",
        "pattern": "3600"
      },
      {
        "type": "hardcoded_values",
        "line": 101,
        "code": "self.allowed_extensions = {'.parquet', '.csv', '.xlsx', '.json'}",
        "description": "ハードコーディング値",
        "severity": "medium",
        "pattern": "\\.parquet"
      },
      {
        "type": "hardcoded_values",
        "line": 101,
        "code": "self.allowed_extensions = {'.parquet', '.csv', '.xlsx', '.json'}",
        "description": "ハードコーディング値",
        "severity": "medium",
        "pattern": "\\.csv"
      },
      {
        "type": "hardcoded_values",
        "line": 102,
        "code": "self.max_file_size = 500 * 1024 * 1024  # 500MB",
        "description": "ハードコーディング値",
        "severity": "medium",
        "pattern": "\\d{4}"
      },
      {
        "type": "hardcoded_values",
        "line": 256,
        "code": "for chunk in iter(lambda: f.read(4096), b\"\"):",
        "description": "ハードコーディング値",
        "severity": "medium",
        "pattern": "\\d{4}"
      },
      {
        "type": "hardcoded_values",
        "line": 299,
        "code": "processing_time = int((datetime.now() - start_time).total_seconds() * 1000)",
        "description": "ハードコーディング値",
        "severity": "medium",
        "pattern": "\\d{4}"
      },
      {
        "type": "hardcoded_values",
        "line": 330,
        "code": "if suffix == '.parquet':",
        "description": "ハードコーディング値",
        "severity": "medium",
        "pattern": "\\.parquet"
      },
      {
        "type": "hardcoded_values",
        "line": 332,
        "code": "elif suffix == '.csv':",
        "description": "ハードコーディング値",
        "severity": "medium",
        "pattern": "\\.csv"
      },
      {
        "type": "hardcoded_values",
        "line": 407,
        "code": "stats['total_size_mb'] += metadata.size_bytes / (1024 * 1024)",
        "description": "ハードコーディング値",
        "severity": "medium",
        "pattern": "\\d{4}"
      },
      {
        "type": "hardcoded_values",
        "line": 453,
        "code": "processing_time = (datetime.now() - start_time).total_seconds() * 1000",
        "description": "ハードコーディング値",
        "severity": "medium",
        "pattern": "\\d{4}"
      },
      {
        "type": "magic_numbers",
        "line": 74,
        "code": "cache_ttl_seconds: int = 3600  # デフォルト1時間",
        "description": "マジックナンバー",
        "severity": "low",
        "pattern": "\\b[0-9]{2,}\\b"
      },
      {
        "type": "magic_numbers",
        "line": 102,
        "code": "self.max_file_size = 500 * 1024 * 1024  # 500MB",
        "description": "マジックナンバー",
        "severity": "low",
        "pattern": "\\b[0-9]{2,}\\b"
      },
      {
        "type": "magic_numbers",
        "line": 256,
        "code": "for chunk in iter(lambda: f.read(4096), b\"\"):",
        "description": "マジックナンバー",
        "severity": "low",
        "pattern": "\\b[0-9]{2,}\\b"
      },
      {
        "type": "magic_numbers",
        "line": 299,
        "code": "processing_time = int((datetime.now() - start_time).total_seconds() * 1000)",
        "description": "マジックナンバー",
        "severity": "low",
        "pattern": "\\b[0-9]{2,}\\b"
      },
      {
        "type": "magic_numbers",
        "line": 407,
        "code": "stats['total_size_mb'] += metadata.size_bytes / (1024 * 1024)",
        "description": "マジックナンバー",
        "severity": "low",
        "pattern": "\\b[0-9]{2,}\\b"
      },
      {
        "type": "magic_numbers",
        "line": 453,
        "code": "processing_time = (datetime.now() - start_time).total_seconds() * 1000",
        "description": "マジックナンバー",
        "severity": "low",
        "pattern": "\\b[0-9]{2,}\\b"
      },
      {
        "type": "complex_conditions",
        "line": 203,
        "code": "elif 'proportional_abolition_org' in name:",
        "description": "複雑な条件分岐",
        "severity": "medium",
        "pattern": "if.*or.*or"
      },
      {
        "type": "complex_conditions",
        "line": 290,
        "code": "if not force_reload and cache_key in self.cache_store:",
        "description": "複雑な条件分岐",
        "severity": "medium",
        "pattern": "if.*or.*or"
      },
      {
        "type": "large_class",
        "class": "UnifiedDataRegistry",
        "method_count": 16,
        "severity": "medium",
        "suggestion": "クラスの分割を検討"
      }
    ]
  },
  "dash_app_integration": [
    {
      "type": "fallback_complexity",
      "count": 22,
      "issue": "統一システム・従来システム間の複雑なフォールバック",
      "severity": "medium",
      "impact": "デバッグ困難、実行パス予測困難"
    }
  ],
  "technical_debt": {
    "architecture_debt": [
      {
        "debt": "データアクセスの二重化",
        "description": "統一システム + 従来システムの並存",
        "impact": "コードの複雑化、テスト困難",
        "cost": "high"
      },
      {
        "debt": "990ファイルスキャンのオーバーヘッド",
        "description": "按分2ファイルのために全ファイルスキャン",
        "impact": "起動時間増加、メモリ使用量増加",
        "cost": "high"
      }
    ],
    "code_debt": [
      {
        "debt": "ハードコーディングされた設定値",
        "description": "キャッシュTTL、ファイル拡張子等",
        "impact": "設定変更が困難、テスト困難",
        "cost": "medium"
      },
      {
        "debt": "複雑な条件分岐",
        "description": "統一システム利用可否の判定ロジック",
        "impact": "バグ混入リスク、理解困難",
        "cost": "medium"
      }
    ],
    "performance_debt": [
      {
        "debt": "I/O集約的な初期化処理",
        "description": "全ファイルのハッシュ計算・メタデータ生成",
        "impact": "初期化時間の大幅増加",
        "cost": "high"
      },
      {
        "debt": "不要なファイルアクセス",
        "description": "按分以外の988ファイルへの無駄アクセス",
        "impact": "リソース浪費、パフォーマンス劣化",
        "cost": "high"
      }
    ]
  },
  "improvements": {
    "immediate_fixes": [
      {
        "title": "条件付きファイルスキャン",
        "description": "特定データタイプのみスキャンする機能追加",
        "implementation": "_scan_available_data(data_types=None) メソッド修正",
        "effort": "low",
        "impact": "high",
        "code_example": "\ndef _scan_available_data(self, target_types: Optional[List[DataType]] = None):\n    # 按分廃止のみの場合は2ファイルのみチェック\n    if target_types == [DataType.PROPORTIONAL_ABOLITION_ROLE, DataType.PROPORTIONAL_ABOLITION_ORG]:\n        specific_files = [\n            \"proportional_abolition_role_summary.parquet\",\n            \"proportional_abolition_organization_summary.parquet\"\n        ]\n        for file_name in specific_files:\n            file_path = Path(\".\") / file_name\n            if file_path.exists():\n                self._register_file(file_path)\n        return\n    \n    # 従来の全ファイルスキャン\n    # ... existing code\n"
      },
      {
        "title": "ハードコード値の設定ファイル化",
        "description": "キャッシュ設定、拡張子等を外部設定に",
        "implementation": "config.json読み込み機能追加",
        "effort": "medium",
        "impact": "medium",
        "code_example": "\n# unified_config.json\n{\n    \"cache_ttl_seconds\": 3600,\n    \"allowed_extensions\": [\".parquet\", \".csv\", \".json\"],\n    \"scan_mode\": \"selective\",  // \"full\" or \"selective\"\n    \"max_file_size_mb\": 100\n}\n"
      }
    ],
    "medium_term_improvements": [
      {
        "title": "段階的初期化",
        "description": "必要な時に必要なデータのみロード",
        "implementation": "lazy loading pattern実装",
        "effort": "medium",
        "impact": "high"
      },
      {
        "title": "キャッシュ戦略最適化",
        "description": "使用頻度に基づく適応的キャッシュ",
        "implementation": "LFU + TTLハイブリッド",
        "effort": "high",
        "impact": "medium"
      }
    ],
    "long_term_improvements": [
      {
        "title": "プラグイン アーキテクチャ",
        "description": "分析タイプ別の独立モジュール化",
        "implementation": "データローダーのプラグイン化",
        "effort": "high",
        "impact": "high"
      }
    ]
  },
  "action_plan": {
    "phase1_immediate": {
      "duration": "1-2時間",
      "actions": [
        "条件付きファイルスキャン実装（990→2ファイル化）",
        "パフォーマンス測定追加（初期化時間計測）",
        "不要ログ出力削減"
      ],
      "expected_improvement": "初期化時間80-90%短縮"
    },
    "phase2_optimization": {
      "duration": "4-6時間",
      "actions": [
        "ハードコード値設定ファイル化",
        "エラーハンドリング簡素化",
        "キャッシュ戦略見直し"
      ],
      "expected_improvement": "保守性向上、設定変更容易化"
    },
    "phase3_architecture": {
      "duration": "1-2日",
      "actions": [
        "データローダーのモジュール化",
        "プラグイン機構検討",
        "総合テスト強化"
      ],
      "expected_improvement": "長期保守性向上、拡張性確保"
    }
  },
  "metadata": {
    "timestamp": "20250809_000146",
    "analysis_scope": "統一システム継続前提でのコーディング問題",
    "key_finding": "990ファイルスキャンが最大の技術的問題"
  }
}