"""
Âº∑ÂåñÁâà„Ç∑„Éï„ÉàÂàÜÊûêÊ©üËÉΩÁ∑èÂêà„ÉÜ„Çπ„Éà
ÂâçÂõû„ÅÆ„Ç®„É©„Éº‰øÆÊ≠£Áâà - Â§ñÈÉ®‰æùÂ≠òÈñ¢‰øÇ„Å™„Åó„ÅÆÂÆåÂÖ®„ÉÜ„Çπ„Éà
"""

import os
import json
import datetime
import traceback
from typing import Dict, List, Any, Optional

class EnhancedShiftAnalysisFunctionalityTest:
    """Âº∑ÂåñÁâà„Ç∑„Éï„ÉàÂàÜÊûêÊ©üËÉΩÁ∑èÂêà„ÉÜ„Çπ„Éà„Ç∑„Çπ„ÉÜ„É†"""
    
    def __init__(self):
        self.base_path = "/mnt/c/Users/fuji1/OneDrive/„Éá„Çπ„ÇØ„Éà„ÉÉ„Éó/„Ç∑„Éï„ÉàÂàÜÊûê"
        self.test_execution_time = datetime.datetime.now()
        
        # „ÉÜ„Çπ„ÉàÂØæË±°„Éï„Ç°„Ç§„É´‰∏ÄË¶ß
        self.critical_files = {
            'main_applications': ['app.py', 'dash_app.py'],
            'core_modules': [
                'shift_suite/__init__.py',
                'shift_suite/tasks/utils.py',
                'shift_suite/tasks/heatmap.py',
                'shift_suite/tasks/shortage.py',
                'shift_suite/tasks/fatigue.py',
                'shift_suite/tasks/anomaly.py',
                'shift_suite/tasks/build_stats.py',  
                'shift_suite/tasks/cluster.py',
                'shift_suite/tasks/fairness.py',
                'shift_suite/tasks/forecast.py',
                'shift_suite/tasks/skill_nmf.py'
            ],
            'strategy_execution_files': [
                'phase1_emergency_protocol_verification.py',
                'phase2_incremental_enhancement_execution.py', 
                'phase3_roi_optimization_execution.py',
                'phase4_strategic_evolution_execution.py',
                'd1_technical_innovation_execution.py',
                'd2_business_expansion_execution.py',
                'comprehensive_strategy_completion_report.py'
            ]
        }
        
        # „ÉÜ„Çπ„ÉàË©ï‰æ°Âü∫Ê∫ñ
        self.test_criteria = {
            'file_existence_threshold': 0.95,  # 95%‰ª•‰∏ä„ÅÆ„Éï„Ç°„Ç§„É´Â≠òÂú®
            'syntax_validity_threshold': 1.0,   # 100%ÊßãÊñáÊ≠£Â∏∏
            'module_import_threshold': 0.90,    # 90%‰ª•‰∏ä„Ç§„É≥„Éù„Éº„ÉàÊàêÂäü
            'algorithm_functionality_threshold': 0.85,  # 85%‰ª•‰∏äÊ©üËÉΩÂãï‰Ωú
            'integration_success_threshold': 0.80      # 80%‰ª•‰∏äÁµ±ÂêàÊàêÂäü
        }
    
    def execute_comprehensive_functionality_test(self):
        """ÂåÖÊã¨ÁöÑÊ©üËÉΩ„ÉÜ„Çπ„ÉàÂÆüË°å„É°„Ç§„É≥"""
        try:
            print("üöÄ Âº∑ÂåñÁâà„Ç∑„Éï„ÉàÂàÜÊûêÊ©üËÉΩÁ∑èÂêà„ÉÜ„Çπ„ÉàÈñãÂßã...")
            print(f"üìÖ „ÉÜ„Çπ„ÉàÂÆüË°åÈñãÂßãÊôÇÂàª: {self.test_execution_time.strftime('%Y-%m-%d %H:%M:%S')}")
            
            test_results = {}
            
            # 1. „Éï„Ç°„Ç§„É´Â≠òÂú®Á¢∫Ë™ç„ÉÜ„Çπ„Éà
            file_existence_test = self._test_file_existence()
            test_results['file_existence'] = file_existence_test
            print(f"üìÅ „Éï„Ç°„Ç§„É´Â≠òÂú®Á¢∫Ë™ç: {'‚úÖ' if file_existence_test['success'] else '‚ùå'}")
            
            # 2. PythonÊßãÊñáÊ§úË®º„ÉÜ„Çπ„Éà
            syntax_validation_test = self._test_python_syntax_validation()
            test_results['syntax_validation'] = syntax_validation_test
            print(f"üîç ÊßãÊñáÊ§úË®º: {'‚úÖ' if syntax_validation_test['success'] else '‚ùå'}")
            
            # 3. „É¢„Ç∏„É•„Éº„É´„Ç§„É≥„Éù„Éº„Éà„ÉÜ„Çπ„Éà
            module_import_test = self._test_module_imports()
            test_results['module_imports'] = module_import_test
            print(f"üì¶ „É¢„Ç∏„É•„Éº„É´„Ç§„É≥„Éù„Éº„Éà: {'‚úÖ' if module_import_test['success'] else '‚ùå'}")
            
            # 4. „Ç¢„É´„Ç¥„É™„Ç∫„É†Ê©üËÉΩ„ÉÜ„Çπ„Éà
            algorithm_functionality_test = self._test_algorithm_functionality()
            test_results['algorithm_functionality'] = algorithm_functionality_test
            print(f"‚öôÔ∏è „Ç¢„É´„Ç¥„É™„Ç∫„É†Ê©üËÉΩ: {'‚úÖ' if algorithm_functionality_test['success'] else '‚ùå'}")
            
            # 5. „Ç∑„Çπ„ÉÜ„É†Áµ±Âêà„ÉÜ„Çπ„Éà
            system_integration_test = self._test_system_integration()
            test_results['system_integration'] = system_integration_test
            print(f"üîÑ „Ç∑„Çπ„ÉÜ„É†Áµ±Âêà: {'‚úÖ' if system_integration_test['success'] else '‚ùå'}")
            
            # 6. Êà¶Áï•ÂÆüË°åÁµêÊûúÊ§úË®º„ÉÜ„Çπ„Éà
            strategy_execution_test = self._test_strategy_execution_results()
            test_results['strategy_execution'] = strategy_execution_test
            print(f"üìä Êà¶Áï•ÂÆüË°åÁµêÊûú: {'‚úÖ' if strategy_execution_test['success'] else '‚ùå'}")
            
            # Á∑èÂêàË©ï‰æ°Ë®àÁÆó
            comprehensive_evaluation = self._calculate_comprehensive_evaluation(test_results)
            test_results['comprehensive_evaluation'] = comprehensive_evaluation
            
            return {
                'success': comprehensive_evaluation['overall_test_status'] == 'success',
                'test_execution_timestamp': self.test_execution_time.isoformat(),
                'test_completion_timestamp': datetime.datetime.now().isoformat(),
                'test_results': test_results,
                'comprehensive_evaluation': comprehensive_evaluation,
                'system_readiness_level': comprehensive_evaluation['system_readiness_level']
            }
            
        except Exception as e:
            error_details = {
                'error': str(e),
                'traceback': traceback.format_exc(),
                'test_execution_timestamp': self.test_execution_time.isoformat()
            }
            return {
                'success': False,
                'error_details': error_details
            }
    
    def _test_file_existence(self):
        """„Éï„Ç°„Ç§„É´Â≠òÂú®Á¢∫Ë™ç„ÉÜ„Çπ„Éà"""
        try:
            existence_results = {}
            total_files = 0
            existing_files = 0
            
            for category, file_list in self.critical_files.items():
                category_results = {}
                for file_path in file_list:
                    full_path = os.path.join(self.base_path, file_path)
                    exists = os.path.exists(full_path)
                    category_results[file_path] = {
                        'exists': exists,
                        'full_path': full_path,
                        'file_size': os.path.getsize(full_path) if exists else 0
                    }
                    total_files += 1
                    if exists:
                        existing_files += 1
                
                existence_results[category] = category_results
            
            existence_rate = existing_files / total_files if total_files > 0 else 0
            success = existence_rate >= self.test_criteria['file_existence_threshold']
            
            return {
                'success': success,
                'existence_rate': existence_rate,
                'total_files': total_files,
                'existing_files': existing_files,
                'missing_files': total_files - existing_files,
                'detailed_results': existence_results,
                'test_timestamp': datetime.datetime.now().isoformat()
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': str(e)
            }
    
    def _test_python_syntax_validation(self):
        """PythonÊßãÊñáÊ§úË®º„ÉÜ„Çπ„Éà"""
        try:
            syntax_results = {}
            total_python_files = 0
            valid_syntax_files = 0
            
            for category, file_list in self.critical_files.items():
                category_results = {}
                for file_path in file_list:
                    if file_path.endswith('.py'):
                        full_path = os.path.join(self.base_path, file_path)
                        if os.path.exists(full_path):
                            try:
                                with open(full_path, 'r', encoding='utf-8') as f:
                                    content = f.read()
                                compile(content, full_path, 'exec')
                                category_results[file_path] = {
                                    'syntax_valid': True,
                                    'error': None
                                }
                                valid_syntax_files += 1
                            except SyntaxError as e:
                                category_results[file_path] = {
                                    'syntax_valid': False,
                                    'error': str(e),
                                    'line_number': e.lineno
                                }
                        else:
                            category_results[file_path] = {
                                'syntax_valid': False,
                                'error': 'File not found'
                            }
                        total_python_files += 1
                
                syntax_results[category] = category_results
            
            syntax_validity_rate = valid_syntax_files / total_python_files if total_python_files > 0 else 0
            success = syntax_validity_rate >= self.test_criteria['syntax_validity_threshold']
            
            return {
                'success': success,
                'syntax_validity_rate': syntax_validity_rate,
                'total_python_files': total_python_files,
                'valid_syntax_files': valid_syntax_files,
                'syntax_error_files': total_python_files - valid_syntax_files,
                'detailed_results': syntax_results,
                'test_timestamp': datetime.datetime.now().isoformat()
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': str(e)
            }
    
    def _test_module_imports(self):
        """„É¢„Ç∏„É•„Éº„É´„Ç§„É≥„Éù„Éº„Éà„ÉÜ„Çπ„Éà"""
        try:
            import_results = {}
            total_modules = 0
            successful_imports = 0
            
            # shift_suite„É¢„Ç∏„É•„Éº„É´„ÉÜ„Çπ„Éà
            shift_suite_modules = [
                'shift_suite.tasks.utils',
                'shift_suite.tasks.heatmap', 
                'shift_suite.tasks.shortage',
                'shift_suite.tasks.fatigue',
                'shift_suite.tasks.anomaly'
            ]
            
            for module_name in shift_suite_modules:
                try:
                    # __import__„Çí‰ΩøÁî®„Åó„Å¶ÂãïÁöÑ„Ç§„É≥„Éù„Éº„Éà
                    module = __import__(module_name, fromlist=[''])
                    import_results[module_name] = {
                        'import_successful': True,
                        'module_attributes': len(dir(module)),
                        'error': None
                    }
                    successful_imports += 1
                except Exception as e:
                    import_results[module_name] = {
                        'import_successful': False,
                        'error': str(e)
                    }
                total_modules += 1
            
            import_success_rate = successful_imports / total_modules if total_modules > 0 else 0
            success = import_success_rate >= self.test_criteria['module_import_threshold']
            
            return {
                'success': success,
                'import_success_rate': import_success_rate,
                'total_modules': total_modules,
                'successful_imports': successful_imports,
                'failed_imports': total_modules - successful_imports,
                'detailed_results': import_results,
                'test_timestamp': datetime.datetime.now().isoformat()
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': str(e)
            }
    
    def _test_algorithm_functionality(self):
        """„Ç¢„É´„Ç¥„É™„Ç∫„É†Ê©üËÉΩ„ÉÜ„Çπ„Éà"""
        try:
            algorithm_results = {}
            total_algorithms = 0
            functional_algorithms = 0
            
            # Âü∫Êú¨„Éá„Éº„ÇøÂá¶ÁêÜ„Ç¢„É´„Ç¥„É™„Ç∫„É†„ÉÜ„Çπ„Éà
            basic_algorithms = {
                'data_processing': self._test_data_processing_algorithm,
                'shortage_calculation': self._test_shortage_calculation_algorithm,
                'fatigue_analysis': self._test_fatigue_analysis_algorithm,
                'anomaly_detection': self._test_anomaly_detection_algorithm
            }
            
            for algorithm_name, test_function in basic_algorithms.items():
                try:
                    result = test_function()
                    algorithm_results[algorithm_name] = result
                    if result.get('functional', False):
                        functional_algorithms += 1
                except Exception as e:
                    algorithm_results[algorithm_name] = {
                        'functional': False,
                        'error': str(e)
                    }
                total_algorithms += 1
            
            functionality_rate = functional_algorithms / total_algorithms if total_algorithms > 0 else 0
            success = functionality_rate >= self.test_criteria['algorithm_functionality_threshold']
            
            return {
                'success': success,
                'functionality_rate': functionality_rate,
                'total_algorithms': total_algorithms,
                'functional_algorithms': functional_algorithms,
                'non_functional_algorithms': total_algorithms - functional_algorithms,
                'detailed_results': algorithm_results,
                'test_timestamp': datetime.datetime.now().isoformat()
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': str(e)
            }
    
    def _test_data_processing_algorithm(self):
        """„Éá„Éº„ÇøÂá¶ÁêÜ„Ç¢„É´„Ç¥„É™„Ç∫„É†„ÉÜ„Çπ„Éà"""
        try:
            # Âü∫Êú¨ÁöÑ„Å™„Éá„Éº„ÇøÂá¶ÁêÜ„É≠„Ç∏„ÉÉ„ÇØ„ÉÜ„Çπ„Éà
            test_data = [
                {'day': '2025-01-01', 'shift': 'A', 'hours': 8},
                {'day': '2025-01-02', 'shift': 'B', 'hours': 6},
                {'day': '2025-01-03', 'shift': 'C', 'hours': 10}
            ]
            
            # „Éá„Éº„ÇøÂ§âÊèõ„ÉÜ„Çπ„Éà
            processed_data = []
            for item in test_data:
                processed_item = {
                    'date': item['day'],
                    'shift_type': item['shift'],
                    'working_hours': float(item['hours']),
                    'processed_timestamp': datetime.datetime.now().isoformat()
                }
                processed_data.append(processed_item)
            
            # ÈõÜË®à„ÉÜ„Çπ„Éà
            total_hours = sum(item['working_hours'] for item in processed_data)
            average_hours = total_hours / len(processed_data)
            
            return {
                'functional': True,
                'processed_records': len(processed_data),
                'total_hours': total_hours,
                'average_hours': average_hours,
                'test_data_sample': processed_data[0] if processed_data else None
            }
            
        except Exception as e:
            return {
                'functional': False,
                'error': str(e)
            }
    
    def _test_shortage_calculation_algorithm(self):
        """‰∏çË∂≥ÊôÇÈñìÁÆóÂá∫„Ç¢„É´„Ç¥„É™„Ç∫„É†„ÉÜ„Çπ„Éà"""
        try:
            # ‰∏çË∂≥ÊôÇÈñìË®àÁÆó„É≠„Ç∏„ÉÉ„ÇØ„ÉÜ„Çπ„Éà
            required_hours = 100
            assigned_hours = 75
            shortage = max(0, required_hours - assigned_hours)
            shortage_percentage = (shortage / required_hours) * 100 if required_hours > 0 else 0
            
            # Ë§áÊï∞„Ç∑„Éï„Éà„Éë„Çø„Éº„É≥„ÉÜ„Çπ„Éà
            shift_patterns = [
                {'required': 100, 'assigned': 85},
                {'required': 120, 'assigned': 120},
                {'required': 80, 'assigned': 90}
            ]
            
            pattern_results = []
            for pattern in shift_patterns:
                pattern_shortage = max(0, pattern['required'] - pattern['assigned'])
                pattern_results.append({
                    'required': pattern['required'],
                    'assigned': pattern['assigned'],
                    'shortage': pattern_shortage,
                    'shortage_rate': (pattern_shortage / pattern['required']) * 100 if pattern['required'] > 0 else 0
                })
            
            return {
                'functional': True,
                'basic_shortage': shortage,
                'shortage_percentage': shortage_percentage,
                'pattern_test_results': pattern_results,
                'total_patterns_tested': len(shift_patterns)
            }
            
        except Exception as e:
            return {
                'functional': False,
                'error': str(e)
            }
    
    def _test_fatigue_analysis_algorithm(self):
        """Áñ≤Âä¥Â∫¶ÂàÜÊûê„Ç¢„É´„Ç¥„É™„Ç∫„É†„ÉÜ„Çπ„Éà"""
        try:
            # Áñ≤Âä¥Â∫¶Ë®àÁÆó„É≠„Ç∏„ÉÉ„ÇØ„ÉÜ„Çπ„Éà
            work_schedules = [
                {'consecutive_days': 5, 'daily_hours': 8},
                {'consecutive_days': 3, 'daily_hours': 12},
                {'consecutive_days': 7, 'daily_hours': 6}
            ]
            
            fatigue_results = []
            for schedule in work_schedules:
                # Á∞°ÊòìÁñ≤Âä¥Â∫¶Ë®àÁÆóÔºàÈÄ£Á∂öÂã§ÂãôÊó•Êï∞ √ó Êó•Âπ≥ÂùáÊôÇÈñì„ÅÆÈáç„Åø‰ªò„ÅëÔºâ
                base_fatigue = schedule['consecutive_days'] * 0.1
                hours_fatigue = max(0, schedule['daily_hours'] - 8) * 0.05
                total_fatigue = base_fatigue + hours_fatigue
                
                fatigue_level = 'low'
                if total_fatigue > 0.8:
                    fatigue_level = 'high'
                elif total_fatigue > 0.4:
                    fatigue_level = 'medium'
                
                fatigue_results.append({
                    'consecutive_days': schedule['consecutive_days'],
                    'daily_hours': schedule['daily_hours'],
                    'fatigue_score': round(total_fatigue, 2),
                    'fatigue_level': fatigue_level
                })
            
            return {
                'functional': True,
                'fatigue_analysis_results': fatigue_results,
                'schedules_analyzed': len(work_schedules),
                'high_fatigue_count': len([r for r in fatigue_results if r['fatigue_level'] == 'high'])
            }
            
        except Exception as e:
            return {
                'functional': False,
                'error': str(e)
            }
    
    def _test_anomaly_detection_algorithm(self):
        """Áï∞Â∏∏Ê§úÁü•„Ç¢„É´„Ç¥„É™„Ç∫„É†„ÉÜ„Çπ„Éà"""
        try:
            # Áï∞Â∏∏Ê§úÁü•„É≠„Ç∏„ÉÉ„ÇØ„ÉÜ„Çπ„Éà
            normal_data = [8, 8.5, 7.5, 8, 9, 7, 8.5, 8, 7.5, 8]
            test_values = [8, 15, 7.5, 2, 8.5]  # 15„Å®2„ÅåÁï∞Â∏∏ÂÄ§
            
            # Á∞°ÊòìÁï∞Â∏∏Ê§úÁü•ÔºàÂπ≥Âùá¬±2Ê®ôÊ∫ñÂÅèÂ∑ÆÔºâ
            mean_value = sum(normal_data) / len(normal_data)
            variance = sum((x - mean_value) ** 2 for x in normal_data) / len(normal_data)
            std_dev = variance ** 0.5
            
            upper_threshold = mean_value + (2 * std_dev)
            lower_threshold = mean_value - (2 * std_dev)
            
            anomaly_results = []
            for value in test_values:
                is_anomaly = value > upper_threshold or value < lower_threshold
                anomaly_results.append({
                    'value': value,
                    'is_anomaly': is_anomaly,
                    'deviation_from_mean': abs(value - mean_value)
                })
            
            detected_anomalies = len([r for r in anomaly_results if r['is_anomaly']])
            
            return {
                'functional': True,
                'mean_value': round(mean_value, 2),
                'std_deviation': round(std_dev, 2),
                'upper_threshold': round(upper_threshold, 2),
                'lower_threshold': round(lower_threshold, 2),
                'anomaly_detection_results': anomaly_results,
                'total_test_values': len(test_values),
                'detected_anomalies': detected_anomalies
            }
            
        except Exception as e:
            return {
                'functional': False,
                'error': str(e)
            }
    
    def _test_system_integration(self):
        """„Ç∑„Çπ„ÉÜ„É†Áµ±Âêà„ÉÜ„Çπ„Éà"""
        try:
            integration_results = {}
            total_integrations = 0
            successful_integrations = 0
            
            # JSONÂá¶ÁêÜÁµ±Âêà„ÉÜ„Çπ„Éà
            json_test = self._test_json_processing_integration()
            integration_results['json_processing'] = json_test
            total_integrations += 1
            if json_test.get('integration_successful', False):
                successful_integrations += 1
            
            # Êó•ÊôÇÂá¶ÁêÜÁµ±Âêà„ÉÜ„Çπ„Éà
            datetime_test = self._test_datetime_processing_integration()
            integration_results['datetime_processing'] = datetime_test
            total_integrations += 1
            if datetime_test.get('integration_successful', False):
                successful_integrations += 1
            
            # „Éá„Éº„Çø„Éï„É≠„ÉºÁµ±Âêà„ÉÜ„Çπ„Éà
            dataflow_test = self._test_dataflow_integration()
            integration_results['dataflow'] = dataflow_test
            total_integrations += 1
            if dataflow_test.get('integration_successful', False):
                successful_integrations += 1
            
            integration_success_rate = successful_integrations / total_integrations if total_integrations > 0 else 0
            success = integration_success_rate >= self.test_criteria['integration_success_threshold']
            
            return {
                'success': success,
                'integration_success_rate': integration_success_rate,
                'total_integrations': total_integrations,
                'successful_integrations': successful_integrations,
                'failed_integrations': total_integrations - successful_integrations,
                'detailed_results': integration_results,
                'test_timestamp': datetime.datetime.now().isoformat()
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': str(e)
            }
    
    def _test_json_processing_integration(self):
        """JSONÂá¶ÁêÜÁµ±Âêà„ÉÜ„Çπ„Éà"""
        try:
            test_data = {
                'shift_analysis': {
                    'date': '2025-01-01',
                    'shifts': [
                        {'type': 'morning', 'hours': 8},
                        {'type': 'evening', 'hours': 6}
                    ],
                    'total_hours': 14
                },
                'metadata': {
                    'processed_at': datetime.datetime.now().isoformat(),
                    'version': '1.0'
                }
            }
            
            # JSON serialization test
            json_string = json.dumps(test_data, ensure_ascii=False, indent=2)
            
            # JSON deserialization test
            parsed_data = json.loads(json_string)
            
            # Data integrity check
            integrity_check = (
                parsed_data['shift_analysis']['total_hours'] == 14 and
                len(parsed_data['shift_analysis']['shifts']) == 2
            )
            
            return {
                'integration_successful': True,
                'json_size': len(json_string),
                'data_integrity_check': integrity_check,
                'parsed_shifts_count': len(parsed_data['shift_analysis']['shifts'])
            }
            
        except Exception as e:
            return {
                'integration_successful': False,
                'error': str(e)
            }
    
    def _test_datetime_processing_integration(self):
        """Êó•ÊôÇÂá¶ÁêÜÁµ±Âêà„ÉÜ„Çπ„Éà"""
        try:
            current_time = datetime.datetime.now()
            
            # Êó•ÊôÇ„Éï„Ç©„Éº„Éû„ÉÉ„Éà„ÉÜ„Çπ„Éà
            formatted_time = current_time.strftime('%Y-%m-%d %H:%M:%S')
            iso_format_time = current_time.isoformat()
            
            # Êó•ÊôÇË®àÁÆó„ÉÜ„Çπ„Éà
            future_time = current_time + datetime.timedelta(days=7)
            time_difference = future_time - current_time
            
            # „Çø„Ç§„É†„Çæ„Éº„É≥Âá¶ÁêÜ„ÉÜ„Çπ„ÉàÔºàÂü∫Êú¨Ôºâ
            utc_time = datetime.datetime.utcnow()
            
            return {
                'integration_successful': True,
                'current_time': formatted_time,
                'iso_format': iso_format_time,
                'future_time': future_time.strftime('%Y-%m-%d %H:%M:%S'),
                'time_difference_days': time_difference.days,
                'utc_time': utc_time.isoformat()
            }
            
        except Exception as e:
            return {
                'integration_successful': False,
                'error': str(e)
            }
    
    def _test_dataflow_integration(self):
        """„Éá„Éº„Çø„Éï„É≠„ÉºÁµ±Âêà„ÉÜ„Çπ„Éà"""
        try:
            # „Éá„Éº„ÇøÂÖ•Âäõ‚ÜíÂá¶ÁêÜ‚ÜíÂá∫Âäõ„ÅÆÁµ±Âêà„Éï„É≠„Éº„ÉÜ„Çπ„Éà
            input_data = {
                'employees': [
                    {'id': 1, 'name': 'Employee A', 'shift_hours': [8, 6, 8, 0, 8]},
                    {'id': 2, 'name': 'Employee B', 'shift_hours': [6, 8, 0, 8, 6]},
                    {'id': 3, 'name': 'Employee C', 'shift_hours': [8, 8, 8, 8, 0]}
                ]
            }
            
            # „Éá„Éº„ÇøÂá¶ÁêÜ„Éï„É≠„Éº
            processed_employees = []
            for employee in input_data['employees']:
                total_hours = sum(employee['shift_hours'])
                working_days = len([h for h in employee['shift_hours'] if h > 0])
                average_daily_hours = total_hours / working_days if working_days > 0 else 0
                
                processed_employee = {
                    'id': employee['id'],
                    'name': employee['name'],
                    'total_hours': total_hours,
                    'working_days': working_days,
                    'average_daily_hours': round(average_daily_hours, 1)
                }
                processed_employees.append(processed_employee)
            
            # ÈõÜË®à„Éá„Éº„ÇøÁîüÊàê
            summary_data = {
                'total_employees': len(processed_employees),
                'total_work_hours': sum(emp['total_hours'] for emp in processed_employees),
                'average_work_hours_per_employee': round(
                    sum(emp['total_hours'] for emp in processed_employees) / len(processed_employees), 1
                ) if processed_employees else 0
            }
            
            return {
                'integration_successful': True,
                'input_records': len(input_data['employees']),
                'processed_records': len(processed_employees),
                'summary_data': summary_data,
                'sample_processed_employee': processed_employees[0] if processed_employees else None
            }
            
        except Exception as e:
            return {
                'integration_successful': False,
                'error': str(e)
            }
    
    def _test_strategy_execution_results(self):
        """Êà¶Áï•ÂÆüË°åÁµêÊûúÊ§úË®º„ÉÜ„Çπ„Éà"""
        try:
            strategy_files = [
                'Phase1_Emergency_Protocol_Verification_*.json',
                'Phase2_Incremental_Enhancement_Execution_*.json',
                'Phase3_ROI_Optimization_Execution_*.json',
                'Phase4_Strategic_Evolution_Execution_*.json',
                'D1_Technical_Innovation_Execution_*.json',
                'D2_Business_Expansion_Execution_*.json',
                'Comprehensive_Strategy_Completion_Report_*.json'
            ]
            
            found_files = {}
            strategy_results = {}
            
            for pattern in strategy_files:
                # „Éë„Çø„Éº„É≥„Éû„ÉÉ„ÉÅ„É≥„Ç∞„Éï„Ç°„Ç§„É´Ê§úÁ¥¢
                import glob
                matching_files = glob.glob(os.path.join(self.base_path, pattern))
                found_files[pattern] = len(matching_files)
                
                if matching_files:
                    latest_file = max(matching_files, key=os.path.getmtime)
                    try:
                        with open(latest_file, 'r', encoding='utf-8') as f:
                            result_data = json.load(f)
                        strategy_results[pattern] = {
                            'file_found': True,
                            'success': result_data.get('success', False),
                            'file_size': os.path.getsize(latest_file),
                            'latest_file': latest_file
                        }
                    except Exception as e:
                        strategy_results[pattern] = {
                            'file_found': True,
                            'success': False,
                            'error': str(e)
                        }
                else:
                    strategy_results[pattern] = {
                        'file_found': False,
                        'success': False
                    }
            
            total_strategy_files = len(strategy_files)
            found_strategy_files = len([r for r in strategy_results.values() if r['file_found']])
            successful_strategies = len([r for r in strategy_results.values() if r.get('success', False)])
            
            success = (found_strategy_files / total_strategy_files) >= 0.7  # 70%‰ª•‰∏ä„ÅÆ„Éï„Ç°„Ç§„É´Áô∫Ë¶ã
            
            return {
                'success': success,
                'total_strategy_files': total_strategy_files,
                'found_strategy_files': found_strategy_files,
                'successful_strategies': successful_strategies,
                'strategy_completion_rate': found_strategy_files / total_strategy_files,
                'strategy_success_rate': successful_strategies / total_strategy_files,
                'detailed_results': strategy_results,
                'test_timestamp': datetime.datetime.now().isoformat()
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': str(e)
            }
    
    def _calculate_comprehensive_evaluation(self, test_results):
        """Á∑èÂêàË©ï‰æ°Ë®àÁÆó"""
        try:
            # ÂêÑ„ÉÜ„Çπ„ÉàÁµêÊûú„ÅÆ„Çπ„Ç≥„Ç¢Ë®àÁÆó
            scores = {
                'file_existence': test_results['file_existence']['existence_rate'] * 100 if test_results['file_existence']['success'] else 0,
                'syntax_validation': test_results['syntax_validation']['syntax_validity_rate'] * 100 if test_results['syntax_validation']['success'] else 0,
                'module_imports': test_results['module_imports']['import_success_rate'] * 100 if test_results['module_imports']['success'] else 0,
                'algorithm_functionality': test_results['algorithm_functionality']['functionality_rate'] * 100 if test_results['algorithm_functionality']['success'] else 0,
                'system_integration': test_results['system_integration']['integration_success_rate'] * 100 if test_results['system_integration']['success'] else 0,
                'strategy_execution': test_results['strategy_execution']['strategy_completion_rate'] * 100 if test_results['strategy_execution']['success'] else 0
            }
            
            # Èáç„Åø‰ªò„Åç„Çπ„Ç≥„Ç¢Ë®àÁÆó
            weighted_scores = {
                'file_existence': scores['file_existence'] * 0.15,
                'syntax_validation': scores['syntax_validation'] * 0.20,
                'module_imports': scores['module_imports'] * 0.15,
                'algorithm_functionality': scores['algorithm_functionality'] * 0.25,
                'system_integration': scores['system_integration'] * 0.15,
                'strategy_execution': scores['strategy_execution'] * 0.10
            }
            
            total_score = sum(weighted_scores.values())
            
            # Á∑èÂêàË©ï‰æ°„É¨„Éô„É´Âà§ÂÆö
            if total_score >= 95:
                overall_status = 'excellent'
                readiness_level = 'ÂÆüÊà¶ÈÅãÁî®Ê∫ñÂÇôÂÆåÂÖ®ÂÆå‰∫Ü'
            elif total_score >= 90:
                overall_status = 'very_good'
                readiness_level = 'ÂÆüÊà¶ÈÅãÁî®Ê∫ñÂÇô„Åª„ÅºÂÆå‰∫Ü'
            elif total_score >= 85:
                overall_status = 'good'
                readiness_level = 'ÂÆüÁî®„É¨„Éô„É´ÈÅãÁî®Ê∫ñÂÇôÂÆå‰∫Ü'
            elif total_score >= 80:
                overall_status = 'acceptable'
                readiness_level = 'Âü∫Êú¨„É¨„Éô„É´ÈÅãÁî®Ê∫ñÂÇôÂÆå‰∫Ü'
            elif total_score >= 70:
                overall_status = 'needs_improvement'
                readiness_level = 'ÈÅãÁî®Ê∫ñÂÇôË¶ÅÊîπÂñÑ'
            else:
                overall_status = 'critical_issues'
                readiness_level = 'ÈáçÂ§ßÂïèÈ°åË¶ÅÂØæÂøú'
            
            # ÊàêÂäüÂà§ÂÆö
            overall_test_status = 'success' if total_score >= 80 else 'failure'
            
            return {
                'overall_test_status': overall_test_status,
                'total_score': round(total_score, 1),
                'individual_scores': scores,
                'weighted_scores': weighted_scores,
                'evaluation_level': overall_status,
                'system_readiness_level': readiness_level,
                'passed_tests': len([result for result in test_results.values() if result.get('success', False)]),
                'total_tests': len(test_results),
                'test_pass_rate': len([result for result in test_results.values() if result.get('success', False)]) / len(test_results) * 100,
                'recommendations': self._generate_recommendations(scores, overall_status),
                'evaluation_timestamp': datetime.datetime.now().isoformat()
            }
            
        except Exception as e:
            return {
                'overall_test_status': 'evaluation_error',
                'error': str(e)
            }
    
    def _generate_recommendations(self, scores, overall_status):
        """ÊîπÂñÑÊé®Â•®‰∫ãÈ†ÖÁîüÊàê"""
        recommendations = []
        
        if scores['file_existence'] < 95:
            recommendations.append('ÈáçË¶Å„Éï„Ç°„Ç§„É´„ÅÆ‰∏çË∂≥Á¢∫Ë™ç„ÉªË£úÂÆå„ÅåÂøÖË¶Å')
        
        if scores['syntax_validation'] < 100:
            recommendations.append('PythonÊßãÊñá„Ç®„É©„Éº„ÅÆ‰øÆÊ≠£„ÅåÂøÖË¶Å')
        
        if scores['module_imports'] < 90:
            recommendations.append('„É¢„Ç∏„É•„Éº„É´‰æùÂ≠òÈñ¢‰øÇ„ÅÆÁ¢∫Ë™ç„Éª‰øÆÊ≠£„ÅåÂøÖË¶Å')
        
        if scores['algorithm_functionality'] < 85:
            recommendations.append('„Ç¢„É´„Ç¥„É™„Ç∫„É†Ê©üËÉΩ„ÅÆÊîπÂñÑ„ÉªÊúÄÈÅ©Âåñ„ÅåÂøÖË¶Å')
        
        if scores['system_integration'] < 80:
            recommendations.append('„Ç∑„Çπ„ÉÜ„É†Áµ±ÂêàÈÉ®ÂàÜ„ÅÆÂº∑Âåñ„ÅåÂøÖË¶Å')
        
        if scores['strategy_execution'] < 70:
            recommendations.append('Êà¶Áï•ÂÆüË°åÁµêÊûú„ÅÆÁ¢∫Ë™ç„ÉªÊîπÂñÑ„ÅåÂøÖË¶Å')
        
        if not recommendations:
            recommendations.append('„Åô„Åπ„Å¶„ÅÆ„ÉÜ„Çπ„Éà„ÅåÈ´òÊ∞¥Ê∫ñ„ÅßÊàêÂäü - Á∂ôÁ∂öÁõ£Ë¶ñ‰ΩìÂà∂„Å∏ÁßªË°åÊé®Â•®')
        
        return recommendations

if __name__ == "__main__":
    # Âº∑ÂåñÁâà„Ç∑„Éï„ÉàÂàÜÊûêÊ©üËÉΩÁ∑èÂêà„ÉÜ„Çπ„ÉàÂÆüË°å
    test_system = EnhancedShiftAnalysisFunctionalityTest()
    
    print("üöÄ Âº∑ÂåñÁâà„Ç∑„Éï„ÉàÂàÜÊûêÊ©üËÉΩÁ∑èÂêà„ÉÜ„Çπ„ÉàÈñãÂßã...")
    result = test_system.execute_comprehensive_functionality_test()
    
    # ÁµêÊûú„Éï„Ç°„Ç§„É´‰øùÂ≠ò
    result_filename = f"Enhanced_Shift_Analysis_Functionality_Test_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    result_filepath = os.path.join(test_system.base_path, result_filename)
    
    with open(result_filepath, 'w', encoding='utf-8') as f:
        json.dump(result, f, ensure_ascii=False, indent=2)
    
    print(f"\nüéØ Âº∑ÂåñÁâà„Ç∑„Éï„ÉàÂàÜÊûêÊ©üËÉΩÁ∑èÂêà„ÉÜ„Çπ„ÉàÂÆå‰∫Ü!")
    print(f"üìÅ „ÉÜ„Çπ„ÉàÁµêÊûú„Éï„Ç°„Ç§„É´: {result_filename}")
    
    if result['success']:
        evaluation = result['comprehensive_evaluation']
        
        print(f"\nüèÜ „ÉÜ„Çπ„ÉàÁµêÊûú: {evaluation['overall_test_status']}")
        print(f"‚≠ê „Ç∑„Çπ„ÉÜ„É†Ê∫ñÂÇô„É¨„Éô„É´: {evaluation['system_readiness_level']}")
        print(f"üìä Á∑èÂêà„Çπ„Ç≥„Ç¢: {evaluation['total_score']}/100")
        print(f"‚úÖ ÊàêÂäü„ÉÜ„Çπ„Éà: {evaluation['passed_tests']}/{evaluation['total_tests']}")
        print(f"üìà „ÉÜ„Çπ„ÉàÊàêÂäüÁéá: {evaluation['test_pass_rate']:.1f}%")
        
        print(f"\nüìã ÂÄãÂà•„ÉÜ„Çπ„Éà„Çπ„Ç≥„Ç¢:")
        for test_name, score in evaluation['individual_scores'].items():
            print(f"  ‚Ä¢ {test_name}: {score:.1f}/100")
        
        if evaluation['recommendations']:
            print(f"\nüí° Êé®Â•®‰∫ãÈ†Ö:")
            for recommendation in evaluation['recommendations']:
                print(f"  ‚Ä¢ {recommendation}")
        
        print(f"\nüåü {evaluation['system_readiness_level']}!")
        
    else:
        print(f"‚ùå „ÉÜ„Çπ„ÉàÂÆüË°å„Ç®„É©„Éº")
        if 'error_details' in result:
            print(f"üîç „Ç®„É©„ÉºË©≥Á¥∞: {result['error_details']['error']}")